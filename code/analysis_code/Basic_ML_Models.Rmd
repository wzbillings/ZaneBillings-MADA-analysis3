---
title: "Basic ML Models"
author: "Zane Billings"
date: "10/28/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
###############################
# Basic ML models
# Zane Billings
# In this script, I will preprocess the data, and fit a few basic ML models.
# The main outcome here will be Body Temperature, and the models I will fit are:
# 1. Regression tree
# 2. LASSO
# 3. Random forest
###############################

# Packages and setup
library(here)
library(tidymodels)
library(finetune)
library(doParallel)

# Load the data
dat_orig <- readRDS(here::here("data", "processed_data", "processeddata.rds"))

###############################
# Data preprocessing
###############################
# In the previous analysis, we had an issue with rank deficient linear models.
# This was due to having variables for presence/absence AND symptom severity
# for Weakness, Cough, and Myalgia. So we will remove the binary versions.
# We will also ensure that the intensity variables are coded as ordinal vars.
dat <- dat_orig |>
  # Remove the unwanted variables
  dplyr::select(-c(CoughYN, CoughYN2, MyalgiaYN, WeaknessYN)) |>
  # Rename CoughIntensity to Cough to save me 10 seconds of typing
  dplyr::rename(Cough = CoughIntensity) |>
  # Code symptom intensities as ordered factors
  dplyr::mutate(
    dplyr::across(
      .cols = c(Cough, Myalgia, Weakness),
      .fns = ~factor(.x,
                     levels = c("None", "Mild", "Moderate", "Severe"),
                     ordered = TRUE)
    )
  )

# Next, we will remove any binary variables with < 50 events. These variables
# are unlikely to be predictive.
dat <- dat |>
  dplyr::select(
    # Select all variables with at least 50 yes
    where(~sum(.x == "Yes") >= 50),
    # Select all variables where the level set is not c("No", "Yes")
    where(~all(levels(.x) != c("No", "Yes")))
  )

###############################
# Modeling setup
###############################
set.seed(123)

# Before we begin modeling, we will split the data into testing and training
# sets. We will also resample the testing set using CV.
dat_split <- rsample::initial_split(dat, prop = .7, strata = BodyTemp)
train <- rsample::training(dat_split)
test <- rsample::testing(dat_split)
resamples <- rsample::vfold_cv(train, v = 5, repeats = 5, strata = BodyTemp)

# Now we will create a recipe for fitting the models.
bt_rec_int <- recipe(BodyTemp ~ ., data = train) |>
  step_ordinalscore(Cough, Weakness, Myalgia) |>
  step_dummy(all_nominal_predictors())

bt_rec_pol <- recipe(BodyTemp ~ ., data = train) |>
  step_dummy(all_nominal_predictors())

bt_rec_fac <- recipe(BodyTemp ~ ., data = train) |>
  step_mutate(across(c(Cough, Weakness, Myalgia), as.factor)) |>
  step_dummy(all_nominal_predictors())

# Define a metric set so we can tune on RMSE only.
bt_met <- metric_set(rmse)

###############################
# Getting null RMSE
###############################

# I am going to estimate the null RMSE and get the SE by bootstraps.
res <- numeric(1000)
for (i in 1:1000) {
  Bi <- train[sample(1:nrow(train), size = nrow(train), replace = TRUE), "BodyTemp"]
  res[i] <- rmse_vec(
    truth = Bi, estimate = rep(mean(train$BodyTemp), nrow(train))
  )
}
null_rmse <- tibble(
  estimate = rmse_vec(truth = train$BodyTemp,
                      estimate = rep(mean(train$BodyTemp), nrow(train))),
  std_err = sd(res)
)

###############################
# Model specs
###############################
tree_spec <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune(),
  min_n = tune()
) |>
  set_engine("rpart") |>
  set_mode("regression")

lasso_spec <- linear_reg(penalty = tune(), mixture = 1) |>
  set_engine("glmnet") |>
  set_mode("regression")

rf_spec <- rand_forest(mtry = tune(), min_n = tune(), trees = tune()) |>
  set_engine("ranger", num.threads = 8) |>
  set_mode("regression")

###############################
# Regression tree model
###############################

# For the regression tree model, I am going to code the ordinal predictors as
# polynomial contrasts. Since all three of the models we are using have some
# form of variable selection, I think using orthogonal polynomials makes the
# most sense, because if the terms are irrelevant, they can be discarded.

# Create workflow
tree_wf_pol <- workflow() |>
  add_model(tree_spec) |>
  add_recipe(bt_rec_pol)

# For tuning, I was worried about running into a local minimum and not covering
# any better parameter values. So I started with a small grid search and used
# that as the initial parameter guess for simulated annealing.

doParallel::registerDoParallel(cores = 12)

tree_grid <- grid_latin_hypercube(
  cost_complexity(), tree_depth(), min_n(), size = 100
)

tree_pol_grid <- tree_wf_pol |>
  tune_grid(
    resamples = resamples,
    metrics = bt_met,
    control = control_grid(verbose = TRUE),
    grid = tree_grid
  )

tree_pol_sa <- tree_wf_pol %>%
  tune_sim_anneal(
    resamples = resamples,
    metrics = bt_met,
    control = control_sim_anneal(verbose = TRUE),
    iter = 100,
    initial = tree_pol_grid
  )

doParallel::stopImplicitCluster()

# Select best parameter values after optimization
best_tree_pol <- select_best(tree_pol_sa)

# Finalize workflow with best values
final_tree_wf_pol <- tree_wf_pol |>
  finalize_workflow(best_tree_pol)

# Fit model to training data
tree_pol_fit <- final_tree_wf_pol |> fit(data = train)

# Get a plot of the fitted tree
rpart.plot::rpart.plot(tree_pol_fit$fit$fit$fit)

# Plot model predictions vs actual outcomes
tree_pol_res <- tree_pol_fit |>
  augment(new_data = train) |>
  select(.pred, BodyTemp) |>
  dplyr::mutate(.resid = BodyTemp - .pred)

tree_pred_obs_plot <- ggplot(tree_pol_res, aes(x = BodyTemp, y = .pred)) +
  geom_point() +
  cowplot::theme_cowplot() +
  labs(
    title = "Decision tree: predicted vs observed",
    x = "Observed",
    y = "Fitted"
  )

# Plot model predictions vs residuals
tree_pred_res_plot <- ggplot(tree_pol_res, aes(x = .resid, y = .pred)) +
  geom_point() +
  cowplot::theme_cowplot() +
  labs(
    title = "Decision tree: predicted vs residuals",
    x = "Residuals",
    y = "Fitted"
  )

# Get best outcomes
tree

# Compare to null model RMSE

###
# put tree plots together
###

cowplot::plot_grid(
  facp1, intp1, polp1, facp2, intp2, polp2, ncol = 3, nrow = 2
)


# tree_wf <- workflow_set(
#   preproc = list(
#     "unconstrained" = bt_rec_fac,
#     "linear" = bt_rec_int,
#     "polynomial" = bt_rec_pol
#   ),
#   models = list("tree" = tree_spec)
# )
# 
# this <- workflow_map(
#   tree_wf,
#   fn = "tune_grid",
#   verbose = TRUE,
#   seed = 123,
#   resamples = resamples,
#   metrics = bt_met,
#   grid = tree_grid,
#   control = control_grid(verbose = TRUE)
# )


```

